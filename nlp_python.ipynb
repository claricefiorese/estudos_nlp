{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Text Preprocessing"
      ],
      "metadata": {
        "id": "OdmrYDjDq-A_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cleaning & Tokenization"
      ],
      "metadata": {
        "id": "oELA0zZXq-D4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re, nltk\n",
        "from nltk.corpus   import stopwords\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "DkJXT6LDrF5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVjWtnYzrHRN",
        "outputId": "710f4529-9b2a-4e24-cfc4-9e483e81cfd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    tokens = word_tokenize(text)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    return [w for w in tokens if w not in stop_words]"
      ],
      "metadata": {
        "id": "aPJn8AdArJAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stemming vs Lemmatization"
      ],
      "metadata": {
        "id": "xPkfFRhbq-Gn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stemming**\n",
        "- Definição: Stemming é o processo de reduzir uma palavra à sua forma base ou raiz, removendo sufixos e prefixos. O resultado pode não ser uma palavra válida no idioma.\n",
        "- Exemplo: As palavras \"correndo,\" \"corredor\" e \"correu\" podem ser reduzidas a \"corr\".\n",
        "- Método: Utiliza algoritmos como o Porter Stemmer, que aplicam um conjunto de regras para remover afixos.\n",
        "- Prós: É mais rápido e simples.\n",
        "- Contras: Pode ser menos preciso, pois pode gerar palavras inexistentes.\n",
        "\n",
        "**Lematização**\n",
        "- Definição: Lematização é o processo de reduzir uma palavra à sua forma base ou de dicionário, conhecida como lema. Considera o contexto e a parte do discurso da palavra.\n",
        "- Exemplo: As palavras \"correndo\" e \"correu\" seriam reduzidas a \"correr,\" mas \"melhor\" seria reduzido a \"bom.\"\n",
        "- Método: Utiliza um vocabulário e análise morfológica das palavras, frequentemente requerendo um dicionário.\n",
        "- Prós: É mais precisa e produz palavras válidas.\n",
        "- Contras: É mais lenta e complexa.\n",
        "\n",
        "**Comparação**\n",
        "- Precisão: A lematização é geralmente mais precisa que o stemming.\n",
        "- Velocidade: O stemming é mais rápido e simples.\n",
        "- Resultado: A lematização produz palavras válidas, enquanto o stemming pode produzir palavras inexistentes."
      ],
      "metadata": {
        "id": "5UJBilRxq-JP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Stemming with NLTK\n",
        "from nltk.stem import PorterStemmer\n",
        "porter = PorterStemmer()\n",
        "porter.stem('running') # 'run'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "zTpSJq5urPVd",
        "outputId": "50e07c47-80a9-4331-97a6-dc6cb28ab419"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'run'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lemmatization with spaCy\n",
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "doc = nlp('I am running in the park')\n",
        "[token.lemma_ for token in doc] # ['I', 'be', 'run', 'in', 'the', 'park']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XqfuW8GrR7b",
        "outputId": "0e40944c-ab65-4773-f6c8-5ef137ddbf50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I', 'be', 'run', 'in', 'the', 'park']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing Tips**\n",
        "\n",
        "- Always lowercase text for consistency\n",
        "- Remove stopwords for topic modeling, but keep them for sentiment analysis\n",
        "- Use lemmatization over stemming when meaning preservation is important\n",
        "- Consider domain-specific preprocessing (e.g., hashtags for social media)"
      ],
      "metadata": {
        "id": "fz0kS3MgtmAs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Extraction"
      ],
      "metadata": {
        "id": "nVBV3tGWuNWe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bag of Words"
      ],
      "metadata": {
        "id": "iYHzQIx8uTEV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bag of Words (BoW)**\n",
        "\n",
        "- Definição: Bag of Words é uma técnica de representação de texto em que um documento é transformado em um vetor de palavras, ignorando a ordem e a estrutura gramatical. Cada palavra única no documento é considerada uma característica.\n",
        "- Processo:\n",
        "  1. Tokenização: Dividir o texto em palavras individuais (tokens).\n",
        "  2. Construção do vocabulário: Criar uma lista de todas as palavras únicas presentes no texto.\n",
        "  3. Contagem de frequência: Contar quantas vezes cada palavra aparece no texto.\n",
        "\n",
        "**Vetorização**\n",
        "- Definição: Vetorização é o processo de transformar o texto em uma representação numérica (vetor) que pode ser usada por algoritmos de aprendizado de máquina.\n",
        "- Método:\n",
        "  1. Criação do vetor: Cada documento é representado por um vetor onde cada posição corresponde à frequência de uma palavra do vocabulário.\n",
        "  2. Exemplo: Se o vocabulário contém as palavras [\"casa\", \"carro\", \"livro\"], e o documento é \"casa carro casa\", o vetor seria [2, 1, 0], indicando que \"casa\" aparece duas vezes, \"carro\" uma vez, e \"livro\" nenhuma vez.\n",
        "\n",
        "**Aplicações**\n",
        "- Classificação de texto: Usado para categorizar documentos em diferentes classes.\n",
        "- Análise de sentimentos: Determinar o sentimento expresso em um texto.\n",
        "- Recuperação de informação: Encontrar documentos relevantes em grandes conjuntos de dados."
      ],
      "metadata": {
        "id": "26bBOs4pvz5M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "corpus = [\n",
        "    'Natural language processing.',\n",
        "    'I love learning about NLP.'\n",
        "]\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "# Get feature names & document vectors\n",
        "vectorizer.get_feature_names_out()\n",
        "X.toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJYD_KH0uVZ2",
        "outputId": "89c794c0-c952-45ac-e05e-77af15b087e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 0, 0, 1, 0, 1],\n",
              "       [1, 0, 1, 1, 0, 1, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TF-IDF"
      ],
      "metadata": {
        "id": "jnrrAxkLwgYP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TF-IDF (Frequência de Termo-Inverso da Frequência de Documento)**\n",
        "\n",
        "- Definição: TF-IDF é uma técnica de vetorização de texto que avalia a importância de uma palavra em um documento em relação a um conjunto de documentos (corpus). Combina duas métricas: a frequência do termo (TF) e a frequência inversa do documento (IDF).\n",
        "\n",
        "- Componentes\n",
        "\n",
        "  1. Frequência de Termo (TF):\n",
        "\n",
        "    - Definição: A frequência de termo é o número de vezes que uma palavra aparece em um documento.\n",
        "\n",
        "  2. Frequência Inversa de Documento (IDF):\n",
        "\n",
        "    - Definição: A frequência inversa de documento mede a importância de uma palavra em todo o corpus. Palavras comuns em muitos documentos recebem um valor baixo de IDF.\n",
        "\n",
        "- Aplicações\n",
        "\n",
        "  - Classificação de texto: Usado para categorizar documentos com base na importância das palavras.\n",
        "  - Busca de informação: Melhorar a relevância dos resultados de busca.\n",
        "  - Análise de sentimentos: Identificar palavras-chave que indicam sentimentos."
      ],
      "metadata": {
        "id": "VlMGerDTwxKS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "# Get feature names & document vectors\n",
        "vectorizer.get_feature_names_out()\n",
        "X.toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxYGtM-YvaIJ",
        "outputId": "67a0c849-9ac2-4f5a-9751-f3d53191efe1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.57735027, 0.        , 0.        , 0.57735027,\n",
              "        0.        , 0.57735027],\n",
              "       [0.5       , 0.        , 0.5       , 0.5       , 0.        ,\n",
              "        0.5       , 0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word Embeddings"
      ],
      "metadata": {
        "id": "Rl4oD2yVyJ3F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Word Embeddings**\n",
        "\n",
        "- Definição: Word embeddings são representações vetoriais de palavras que capturam seus significados semânticos. Diferente de técnicas como Bag of Words e TF-IDF, que representam palavras como vetores esparsos, word embeddings representam palavras em vetores densos de dimensões menores.\n",
        "\n",
        "Como Funcionam\n",
        "\n",
        "- Treinamento: Word embeddings são treinados em grandes corpora de texto usando algoritmos como Word2Vec, GloVe ou FastText. Esses algoritmos aprendem a representar palavras de forma que palavras com significados semelhantes tenham vetores próximos no espaço vetorial.\n",
        "- Dimensionalidade: Cada palavra é representada por um vetor de várias dimensões (geralmente entre 100 e 300 dimensões).\n",
        "\n",
        "Algoritmos Populares\n",
        "\n",
        "1. Word2Vec:\n",
        "\n",
        "  - Modelos: Skip-gram e Continuous Bag of Words (CBOW).\n",
        "  - Objetivo: Prever palavras contextuais próximas ou prever a palavra central a partir de palavras contextuais.\n",
        "\n",
        "2. GloVe (Global Vectors for Word Representation):\n",
        "\n",
        "  - Baseado em estatísticas: Utiliza a coocorrência global de palavras em um corpus.\n",
        "  - Objetivo: Capturar relações semânticas entre palavras.\n",
        "\n",
        "3. FastText:\n",
        "\n",
        "  - Subpalavras: Considera subpalavras (n-grams) para capturar morfologia.\n",
        "  - Vantagem: Melhor para lidar com palavras raras e novas.\n",
        "\n",
        "Aplicações\n",
        "\n",
        "- Processamento de Linguagem Natural (PLN): Usado em tarefas como tradução automática, análise de sentimentos, e classificação de texto.\n",
        "- Sistemas de Recomendação: Melhorar a recomendação de itens com base em descrições textuais.\n",
        "- Chatbots e Assistentes Virtuais: Melhorar a compreensão e geração de linguagem natural."
      ],
      "metadata": {
        "id": "CwLrqM5H05Ut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade numpy -q\n",
        "!pip install --upgrade gensim -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKjUw7TTydYd",
        "outputId": "1606335a-f19a-46d0-b8d8-ab69878fa76a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.5 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.5 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "sentences = [['natural', 'language'], ['machine', 'learning']]\n",
        "\n",
        "model = Word2Vec(sentences, vector_size=100, window=5, min_count=1)\n",
        "\n",
        "# Get vector & similar words\n",
        "vector = model.wv['natural']\n",
        "similar = model.wv.most_similar('natural', topn=5)"
      ],
      "metadata": {
        "id": "_TK_Hteax3wZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**When to Use Each Feature Type**\n",
        "\n",
        "- BoW/TF-IDF: Text classification, document clustering\n",
        "- Word Embeddings: Semantic tasks, text similarity, transfer learning\n",
        "- Contextual Embeddings: Advanced tasks requiring context understanding"
      ],
      "metadata": {
        "id": "ptAMVxfQz319"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Classification"
      ],
      "metadata": {
        "id": "RHsuo_Zr2MXY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic Pipeline"
      ],
      "metadata": {
        "id": "N0m-jqdU2PtO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes             import MultinomialNB\n",
        "from sklearn.pipeline                import Pipeline"
      ],
      "metadata": {
        "id": "LJiVpYWx2PLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = ['I love this product', 'This is terrible', 'This is perfect']\n",
        "y_train = ['positive', 'negative', 'positive']\n",
        "\n",
        "text_clf = Pipeline([('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])\n",
        "\n",
        "text_clf.fit(X_train, y_train)\n",
        "text_clf.predict(['This was awesome']) # ['positive']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LddQ14DU2g33",
        "outputId": "6bc533db-9e47-4e8b-85ce-fc79fbee2591"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['positive'], dtype='<U8')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using Transformers"
      ],
      "metadata": {
        "id": "Wq52E1DA3mNQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline('sentiment-analysis')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nx64VIPA2g7X",
        "outputId": "999ce11f-d7f3-4c5e-a93f-57ce8c81d254"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = classifier(\"I've been waiting for this movie!\")\n",
        "result # [{'label': 'POSITIVE', 'score': 0.9998}]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kyR2yiX4Vy2",
        "outputId": "9a3e36c1-1477-4cb3-8d78-f50f1e447b68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9878816604614258}]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "|Classification Task |Recommended Approach|\n",
        "|------------|------------|\n",
        "|Sentiment Analysis|VADER (rule-based) or fine-tuned BERT|\n",
        "|Topic Classification|TF-IDF + SVM or DistilBERT|\n",
        "|Intent Recognition|Fine-tuned RoBERTa|\n",
        "|Spam Detection|TF-IDF + Naive Bayes|"
      ],
      "metadata": {
        "id": "r8rTAjqn5cO-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Named Entity Recognition"
      ],
      "metadata": {
        "id": "mlDnXqwx5wpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reconhecimento de Entidades Nomeadas (NER)**\n",
        "\n",
        "- Definição: NER é uma técnica de processamento de linguagem natural (PLN) que identifica e classifica entidades mencionadas em um texto. Essas entidades podem ser pessoas, organizações, locais, datas, valores, entre outras.\n",
        "\n",
        "Como Funciona\n",
        "\n",
        "- Processo:\n",
        "  1. Tokenização: Dividir o texto em palavras ou tokens.\n",
        "  2. Identificação de Entidades: Usar modelos de aprendizado de máquina para identificar palavras ou frases que representam entidades.\n",
        "  3. Classificação: Atribuir uma categoria a cada entidade identificada (por exemplo, pessoa, organização, local).\n",
        "\n",
        "Algoritmos e Modelos\n",
        "\n",
        "- Modelos Baseados em Redes Neurais: Modelos como BiLSTM-CRF e transformers (por exemplo, BERT) são frequentemente usados para NER devido à sua capacidade de capturar contextos complexos.\n",
        "- Embeddings Contextuais: Utilizar embeddings como Word2Vec, GloVe ou FastText para representar palavras em vetores densos que capturam significados semânticos.\n",
        "\n",
        "Aplicações\n",
        "\n",
        "- Extração de Informação: Usado para extrair informações estruturadas de textos não estruturados.\n",
        "- Análise de Sentimentos: Identificar entidades mencionadas em textos e analisar os sentimentos associados.\n",
        "- Sistemas de Busca: Melhorar a relevância dos resultados de busca ao identificar entidades chave."
      ],
      "metadata": {
        "id": "_bexkwaW6abI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exemplo de NER"
      ],
      "metadata": {
        "id": "rvfB4PrR65VY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## spaCy NER"
      ],
      "metadata": {
        "id": "qyz6b4Wp543X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "doc = nlp('Apple is buying U.K. startup for $1 billion')\n",
        "\n",
        "for ent in doc.ents:\n",
        "  print(ent.text, ent.label_)\n",
        "# Apple ORG\n",
        "# U.K. GPE\n",
        "# $1 billion MONEY"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_SYlPwS4W2X",
        "outputId": "0425a0b8-dd9a-4284-e8de-c8456888b891"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apple ORG\n",
            "U.K. GPE\n",
            "$1 billion MONEY\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformers NER"
      ],
      "metadata": {
        "id": "FbdjAef7-_N7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "ner = pipeline('ner')\n",
        "\n",
        "text = 'My name is Sarah and I work at Google in London'\n",
        "ner_results = ner(text)\n",
        "ner_results # [{'entity': 'I-PER', 'score': 0.99, 'word': 'Sarah'}, ...]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdT4OhAf--Xb",
        "outputId": "8640eddd-a26a-4916-ffb9-1aac4a018526"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision 4c53496 (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity': 'I-PER',\n",
              "  'score': 0.9986339,\n",
              "  'index': 4,\n",
              "  'word': 'Sarah',\n",
              "  'start': 11,\n",
              "  'end': 16},\n",
              " {'entity': 'I-ORG',\n",
              "  'score': 0.9985827,\n",
              "  'index': 9,\n",
              "  'word': 'Google',\n",
              "  'start': 31,\n",
              "  'end': 37},\n",
              " {'entity': 'I-LOC',\n",
              "  'score': 0.99839896,\n",
              "  'index': 11,\n",
              "  'word': 'London',\n",
              "  'start': 41,\n",
              "  'end': 47}]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Common Entity Types**\n",
        "\n",
        "- PER/PERSON: People names\n",
        "- ORG: Organizations, companies\n",
        "- LOC/GPE: Locations, geopolitical entities\n",
        "- DATE/TIME: Temporal expressions\n",
        "- MONEY: Monetary values"
      ],
      "metadata": {
        "id": "DEmDbFdWCq18"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment Analysis"
      ],
      "metadata": {
        "id": "a67cmT4ZE-On"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TextBlob"
      ],
      "metadata": {
        "id": "Ibi4V_pdFBEr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "text = 'The movie was absolutely amazing!'\n",
        "blob = TextBlob(text)\n",
        "\n",
        "# Polarity: -1 (negative) to 1 (positive)\n",
        "print(blob.sentiment.polarity) # 0.8\n",
        "\n",
        "# Subjectivity: 0 (objective) to 1 (subjective)\n",
        "print(blob.sentiment.subjectivity) # 0.75"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68IkMcVEFFp6",
        "outputId": "a9c4d6b6-dce6-48af-f1ae-a782c6e0bd48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7500000000000001\n",
            "0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VADER Sentiment"
      ],
      "metadata": {
        "id": "U2fs0AwIHEDu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "import nltk\n",
        "\n",
        "nltk.download('vader_lexicon')\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "text = 'The movie was absolutely amazing!'\n",
        "scores = sia.polarity_scores(text)\n",
        "\n",
        "print(scores) # {'neg': 0.0, 'neu': 0.295, 'pos': 0.705, 'compound': 0.8316}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BROm6nePHJUw",
        "outputId": "ae56906b-a680-4f01-c31c-5c6428d213d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'neg': 0.0, 'neu': 0.477, 'pos': 0.523, 'compound': 0.6581}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sentiment Analysis Tips**\n",
        "\n",
        "- Rule-based approaches work well for straightforward text\n",
        "- Consider using domain-specific models for specialized content\n",
        "- ML/DL approaches handle context, sarcasm, and negation better\n",
        "- Use BERT variants for state-of-the-art performance"
      ],
      "metadata": {
        "id": "02LTwDm6HmOV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Topic Modeling"
      ],
      "metadata": {
        "id": "7vEC5XaJJBCF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LDA with Gensim"
      ],
      "metadata": {
        "id": "Qvx2B1fxJJg5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O **Latent Dirichlet Allocation** (LDA), ou **Alocação Latente de Dirichlet**, é um modelo estatístico utilizado para identificar tópicos ocultos em um conjunto de documentos. Este modelo é amplamente aplicado em áreas como processamento de linguagem natural, mineração de texto e análise de dados.\n",
        "\n",
        "Como funciona o LDA:\n",
        "1. Distribuição de tópicos em documentos: Cada documento é considerado uma mistura de vários tópicos.\n",
        "2. Distribuição de palavras em tópicos: Cada palavra em um documento é atribuída a um tópico específico.\n",
        "\n",
        "Por exemplo, em um conjunto de documentos sobre ciência, um tópico pode incluir palavras como “experimento”, “hipótese” e “resultado”. O modelo atribui probabilidades para a presença de cada tópico em cada documento e a probabilidade de cada palavra pertencer a cada tópico."
      ],
      "metadata": {
        "id": "ROovbVo1PlEN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.corpora import Dictionary\n",
        "from gensim.models  import LdaModel\n",
        "\n",
        "docs = [\n",
        "    'Machine learning is a subset of AI',\n",
        "    'NLP is used for text analysis'\n",
        "    ]\n",
        "\n",
        "# Tokenize\n",
        "tokenized_docs = [doc.lower().split() for doc in docs]\n",
        "\n",
        "# Create dictionary & corpus\n",
        "dictionary = Dictionary(tokenized_docs)\n",
        "corpus = [dictionary.doc2bow(doc) for doc in tokenized_docs]\n",
        "\n",
        "# Train LDA model\n",
        "lda_model = LdaModel(\n",
        "    corpus=corpus,\n",
        "    id2word=dictionary,\n",
        "    num_topics=2,\n",
        "    passes=10\n",
        "    )\n",
        "\n",
        "# Print topics\n",
        "topics = lda_model.print_topics()\n",
        "for topic in topics:\n",
        "  print(topic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WLPkNkwJOOT",
        "outputId": "04fca810-2f65-4aec-ba7d-370a8b8da1a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0, '0.125*\"is\" + 0.124*\"text\" + 0.124*\"used\" + 0.124*\"nlp\" + 0.124*\"analysis\" + 0.124*\"for\" + 0.042*\"a\" + 0.042*\"machine\" + 0.042*\"of\" + 0.042*\"learning\"')\n",
            "(1, '0.115*\"is\" + 0.115*\"subset\" + 0.115*\"ai\" + 0.115*\"learning\" + 0.115*\"of\" + 0.115*\"machine\" + 0.115*\"a\" + 0.039*\"for\" + 0.039*\"analysis\" + 0.039*\"nlp\"')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Topic Modeling Approaches**\n",
        "\n",
        "- LDA: Classic probabilistic approach\n",
        "- NMF: Non-negative Matrix Factorization\n",
        "- BERTopic: Leverages BERT embeddings\n",
        "- Top2Vec: Document embeddings + clustering"
      ],
      "metadata": {
        "id": "EtAItYKrOuy7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Advanced Techniques"
      ],
      "metadata": {
        "id": "kzwGUH0iQASD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Summarization"
      ],
      "metadata": {
        "id": "Alwds6OsQESc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "summarizer = pipeline('summarization')\n",
        "\n",
        "long_text = '''Pope Francis, born Jorge Mario Bergoglio in Argentina, became the 266th pope of the Catholic Church in 2013. Known for his humility and progressive views, he has focused on social justice, environmental issues, and outreach to marginalized communities. His papacy has been marked by efforts to reform the Church and promote inclusivity.'''\n",
        "\n",
        "summary = summarizer(long_text, max_length=50, min_length=15)\n",
        "print(summary[0]['summary_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5qSwPPTQL2L",
        "outputId": "eb57d77c-ca9d-47ea-d00e-0e1079df074f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Pope Francis became the 266th pope of the Catholic Church in 2013 . Known for his humility and progressive views, he has focused on social justice, environmental issues, and outreach to marginalized communities .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Translation"
      ],
      "metadata": {
        "id": "s6PhKqvbQG2_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "translator = pipeline('translation_en_to_fr')\n",
        "\n",
        "translation = translator('Hello, how are you?')\n",
        "print(translation[0]['translation_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncmSiajwTFZT",
        "outputId": "4ecffb3a-2556-4a48-e96d-8ced177d533d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to google-t5/t5-base and revision a9723ea (https://huggingface.co/google-t5/t5-base).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bonjour, comment êtes-vous?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question Answering"
      ],
      "metadata": {
        "id": "KIQtdtSKQKaz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "qa = pipeline('question-answering')\n",
        "\n",
        "context = 'Python is a programming language created by...'\n",
        "question = 'Who created Python?'\n",
        "\n",
        "result = qa(question=question, context=context)\n",
        "print(result['answer'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ojk1WP-FUA8_",
        "outputId": "163ce5f6-74c4-4537-fc14-ff8c02d79f33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 564e9b5 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "|Task|Beginner Approach|Advanced Approach|\n",
        "|------------|------------|------------|\n",
        "|Summarization|Extractive (TextRank)|Abstractive (T5, BART)|\n",
        "|Translation|Pre-trained pipeline|Custom Seq2Seq models|\n",
        "|Q&A|Rule-based systems|Fine-tuned BERT/T5|\n",
        "|Text Generation|Markov Chains|GPT models|"
      ],
      "metadata": {
        "id": "G1T-oHNiVZFO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NLP Project Evaluation & Tips"
      ],
      "metadata": {
        "id": "59F4Qa1FVpzk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation Metrics by Task**\n",
        "\n",
        "- Classification: Accuracy, F1-score, Precision, Recall\n",
        "- NER: F1-score, Precision, Recall (by entity type)\n",
        "- Summarization: ROUGE-N, ROUGE-L, BLEU\n",
        "- Translation: BLEU, METEOR, TER\n",
        "- Generation: Perplexity, human evaluation"
      ],
      "metadata": {
        "id": "cMMJH-ovVsPa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Best Practices for NLP Projects**\n",
        "\n",
        "- Start simple: Try basic models before complex ones\n",
        "- Clean your data thoroughly: Good preprocessing is crucial\n",
        "- Consider context: Many NLP problems need contextual understanding\n",
        "- Leverage pre-trained models: Often outperform models trained from scratch\n",
        "- Handle class imbalance: Use oversampling or adjusted weights\n",
        "- Use cross-validation: Especially for small datasets\n",
        "- Evaluate properly: Choose appropriate metrics for your task"
      ],
      "metadata": {
        "id": "pfH_-u2OVzhq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Latent Dirichlet Allocation (LDA) | Gensim"
      ],
      "metadata": {
        "id": "w7P1XFdeZb37"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para o LDA, entramos com uma quantidade M de documentos, que em si geram N palavras, que são tratadas no modelo gerando K tópicos, que podem ser entendidos como clusters de palavras.\n",
        "\n",
        "Demais outputs que se extraem do modelo, além dos tópicos em si, são a frequência de palavras por tópicos, representado na figura pelo psi.\n",
        "\n",
        "Outro é a distribuição dos tópicos para cada documento phi, ou seja, quanto percentualmente aquele tópico é relevante para documento.\n",
        "\n",
        "Já os principais parâmetros para o modelo em si, α que indica de quantos tópicos os documentos são compostos, que permite ou não uma distribuição de tópicos por documento mais específica — quanto maior, maior a quantidade de tópicos, mais específica a distribuição; e o β que indica de quantas palavras os tópicos são compostos, que permite ou não uma distribuição de palavras por tópico mais específica — quanto maior, maior a quantidade de palavras, mais específica a distribuição."
      ],
      "metadata": {
        "id": "PkrRPCiWZlr0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fluxo**\n",
        "\n",
        "- Tokenização dos tweets\n",
        "- Redução dos tokens para uma seleção de 10 mil tokens mais significativos de acordo com uma amostra de 5 dias consolidados, significância calculada manualmente\n",
        "- Remoção de caracteres especiais e de acentos através de regex e unicode\n",
        "- Remoção de emojis (usando a biblioteca [emoji](https://pypi.org/project/emoji/))\n",
        "- Remoção de stopwords\n",
        "- Aplicação de modelo Bigram\n",
        "- Aplicação de modelo Trigram\n",
        "- Remoção novamente de stopwords"
      ],
      "metadata": {
        "id": "hVbpVY5nZ7Uk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Não foi aplicado nem o processo de stemming nem de lemmatização.\n",
        "\n",
        "O processo de lemmatização não apresenta bons resultados em português, independente da biblioteca utilizada, resultando em algo similar a um processo de stemming.\n",
        "\n",
        "Já o stemming não resultaria em bons tokens, já que um dos objetivos finais da análise é criar word clouds para cada um dos dias que existia dataset.\n",
        "\n",
        "Outro ponto é que ao longo do processamento a lista de stopwords foi aumentando conforme cada dia de processamento."
      ],
      "metadata": {
        "id": "C8qugndhajz4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Não existe biblioteca com inputs suficientes para ter uma lista de stopwords completa (lista de palavras com significado vazio que são removidas do processamento para não poluírem os resultados da modelagem), ou uma biblioteca que permitisse realizar um processo de stemm ou lemma com precisão.\n",
        "\n",
        "Os resultados não foram agradáveis com as soluções disponíveis, como nltk, inclusive com as soluções desenvolvidas específicas para a língua, como a SnowBall.\n",
        "\n",
        "No final, para realizar a análise, foi criada uma lista de stop words manualmente pelo spacy."
      ],
      "metadata": {
        "id": "z92nmFFqbBec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download pt_core_news_sm\n",
        "!pip install pyLDAvis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "HjXBoSC_b25N",
        "outputId": "22d3692e-5db8-46ae-f344-90b672c25201"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pt-core-news-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.8.0/pt_core_news_sm-3.8.0-py3-none-any.whl (13.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m108.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('pt_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Collecting pyLDAvis\n",
            "  Downloading pyLDAvis-3.4.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: numpy>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (1.13.1)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (2.2.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (1.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (3.1.6)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (2.10.2)\n",
            "Collecting funcy (from pyLDAvis)\n",
            "  Downloading funcy-2.0-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (1.6.1)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (4.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (75.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->pyLDAvis) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->pyLDAvis) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->pyLDAvis) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.0->pyLDAvis) (3.6.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim->pyLDAvis) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->pyLDAvis) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->pyLDAvis) (1.17.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim->pyLDAvis) (1.17.2)\n",
            "Downloading pyLDAvis-3.4.1-py3-none-any.whl (2.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading funcy-2.0-py2.py3-none-any.whl (30 kB)\n",
            "Installing collected packages: funcy, pyLDAvis\n",
            "Successfully installed funcy-2.0 pyLDAvis-3.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Bibliotecas gerais\n",
        "import sys\n",
        "import os\n",
        "from pathlib                    import Path\n",
        "import re\n",
        "import numpy                    as np\n",
        "import pandas                   as pd\n",
        "from pprint                     import pprint\n",
        "from tqdm                       import tqdm\n",
        "import pt_core_news_sm\n",
        "\n",
        "# Gensim\n",
        "import gensim, spacy, logging, warnings\n",
        "import gensim.corpora           as corpora\n",
        "from gensim.utils               import simple_preprocess\n",
        "from gensim.models              import CoherenceModel\n",
        "from gensim.models.ldamulticore import LdaMulticore\n",
        "\n",
        "# Plots\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim\n",
        "import matplotlib.pyplot        as plt\n",
        "import matplotlib.colors        as mcolors\n",
        "from wordcloud                  import WordCloud, STOPWORDS\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "tYLUmH4bbXXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texto = '''Pope Francis passed away on Easter Monday, April 21, 2025, at the age of 88. He died at his residence, the Domus Sanctae Marthae in Vatican City, following a stroke and irreversible heart failure. His death was announced by Cardinal Kevin Farrell, the Camerlengo, in a broadcast by Vatican Media. Pope Francis had served as the head of the Catholic Church since his election on March 13, 2013. Known for his humility and efforts to make the Church more inclusive, he often clashed with world leaders over issues such as the rights of immigrants. Despite his health challenges, including chronic lung damage and mobility issues, he remained dedicated to his role and continued to engage with the public. His funeral is scheduled to take place on April 26, 2025, at St. Peter's Square in Vatican City. The papal conclave to elect his successor is expected to begin between May 6 and May 12, 2025. Pope Francis's legacy includes his commitment to living the values of the Gospel with fidelity, courage, and universal love, especially towards the poorest and most marginalized. His passing has prompted global tributes and reflections on his impactful life and service.'''"
      ],
      "metadata": {
        "id": "GTMMgaIdePRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you want to treat the entire 'texto' as a single document\n",
        "tokenized_texto = [texto.lower().split()]\n",
        "\n",
        "# Now create the dictionary\n",
        "id2word = corpora.Dictionary(tokenized_texto)\n",
        "\n",
        "# Proceed with creating the corpus\n",
        "corpus = [id2word.doc2bow(text) for text in tokenized_texto]"
      ],
      "metadata": {
        "id": "qx44CksfeuzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O **valor de coerência** mede, dentro de um único tópico, a coerência semântica das palavras dentro dele, utilizando a métrica de cossenos para sua similaridade, que vai de 0 a 1."
      ],
      "metadata": {
        "id": "JrraRECvkODv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para determinar a melhor quantidade de tópicos para a modelagem\n",
        "\n",
        "def compute_coherence_values(dictionary, corpus, texts, limit, start=1, step=1):\n",
        "  coherence_values = []\n",
        "  model_list = []\n",
        "  for num_topics in tqdm(range(start, limit, step)):\n",
        "    model = LdaMulticore(corpus, id2word=id2word, num_topics=5)\n",
        "    model_list.append(model)\n",
        "    coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
        "    coherence_values.append(coherencemodel.get_coherence())\n",
        "\n",
        "  return model_list, coherence_values"
      ],
      "metadata": {
        "id": "9XNQUzz4jVhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Colocando parâmetros na função\n",
        "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=texto, start=1, limit=10, step=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3h9DX4WKkstS",
        "outputId": "8b66b9c7-891b-457b-ac61-abf16ce10684"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/9 [00:00<?, ?it/s]WARNING:gensim.models.ldamulticore:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            " 11%|█         | 1/9 [00:00<00:01,  4.58it/s]WARNING:gensim.models.ldamulticore:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            " 22%|██▏       | 2/9 [00:00<00:01,  4.43it/s]WARNING:gensim.models.ldamulticore:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            " 33%|███▎      | 3/9 [00:00<00:01,  4.41it/s]WARNING:gensim.models.ldamulticore:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            " 44%|████▍     | 4/9 [00:00<00:01,  4.48it/s]WARNING:gensim.models.ldamulticore:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            " 56%|█████▌    | 5/9 [00:01<00:00,  4.56it/s]WARNING:gensim.models.ldamulticore:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            " 67%|██████▋   | 6/9 [00:01<00:00,  4.55it/s]WARNING:gensim.models.ldamulticore:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            " 78%|███████▊  | 7/9 [00:01<00:00,  4.37it/s]WARNING:gensim.models.ldamulticore:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            " 89%|████████▉ | 8/9 [00:01<00:00,  4.45it/s]WARNING:gensim.models.ldamulticore:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "100%|██████████| 9/9 [00:02<00:00,  4.49it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostrando visualmente a quantidade de tópicos\n",
        "limit=5; start=0; step=1;\n",
        "x = range(start, limit, step)\n",
        "plt.plot(x, coherence_values)\n",
        "plt.xlabel(\"Num Tópicos\")\n",
        "plt.ylabel(\"Score de Coerência\")\n",
        "plt.legend((\"Valores de Coerência\"), loc='best')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "1v45aAUvkVZP",
        "outputId": "516363e8-31f7-4318-ac04-0cb0cff5713d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista dos valores de coerência, para melhor identificar o ponto de inflexão do gráfico\n",
        "for m, cv in zip(x, coherence_values):\n",
        "  print(\"A quantidade de tópicos =\", m, \" tem um valor de coerência de \", round(cv, 4))"
      ],
      "metadata": {
        "id": "08_UQ4MSkymH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}